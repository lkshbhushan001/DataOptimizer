# Removing duplicates:
To remove duplicate rows in a DataFrame, use the `drop_duplicates` method. This ensures that each row is unique based on all or specific columns.

Example:
df.drop_duplicates(inplace=True)

---

# Handling missing values:
Missing values can be handled by filling them with a default value, mean, median, or mode, or by removing rows or columns with missing values.

Example 1: Fill missing values in all numerical columns with the mean:
numerical_columns = df.select_dtypes(include=[np.number]).columns
df[numerical_columns] = df[numerical_columns].apply(lambda col: col.fillna(col.mean()))

Example 2: Fill missing categorical values with the most frequent value (mode):
categorical_columns = df.select_dtypes(include=['object', 'category']).columns
df[categorical_columns] = df[categorical_columns].apply(lambda col: col.fillna(col.mode()[0]))

Example 3: Remove rows where any column has a missing value:
df.dropna(how='any', inplace=True)

---

# Standardizing numerical columns:
Standardization scales the data to have a mean of 0 and a standard deviation of 1. Use the `StandardScaler` from scikit-learn for this task.

Example:
from sklearn.preprocessing import StandardScaler
numerical_columns = df.select_dtypes(include=[np.number]).columns
scaler = StandardScaler()
df[numerical_columns] = scaler.fit_transform(df[numerical_columns])

---

# Normalizing numerical columns:
Normalization scales values to a specific range, such as 0 to 1. Use `MinMaxScaler` for this task.

Example:
from sklearn.preprocessing import MinMaxScaler
numerical_columns = df.select_dtypes(include=[np.number]).columns
scaler = MinMaxScaler()
df[numerical_columns] = scaler.fit_transform(df[numerical_columns])

---

# Binning numerical data:
Bin continuous numerical data into discrete categories or ranges to simplify analysis.

Example: Divide a numerical column into five bins with labels:
numerical_columns = df.select_dtypes(include=[np.number]).columns
bins = [0, 0.2, 0.4, 0.6, 0.8, 1]  # Assuming normalized range [0, 1]
labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']
for col in numerical_columns:
    df[f'binned_{col}'] = pd.cut(df[col], bins=bins, labels=labels)

---

# Encoding categorical variables:
Categorical variables can be converted to numerical formats using one-hot encoding or label encoding.

Example 1: One-hot encoding:
categorical_columns = df.select_dtypes(include=['object', 'category']).columns
df = pd.get_dummies(df, columns=categorical_columns)

Example 2: Label encoding:
from sklearn.preprocessing import LabelEncoder
categorical_columns = df.select_dtypes(include=['object', 'category']).columns
encoder = LabelEncoder()
for col in categorical_columns:
    df[f'encoded_{col}'] = encoder.fit_transform(df[col])

---

# Removing outliers:
Outliers can be removed using statistical methods like IQR or z-scores.

Example 1: IQR method:
numerical_columns = df.select_dtypes(include=[np.number]).columns
for col in numerical_columns:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    df = df[(df[col] >= Q1 - 1.5 * IQR) & (df[col] <= Q3 + 1.5 * IQR)]

Example 2: Remove rows where z-score exceeds 3:
numerical_columns = df.select_dtypes(include=[np.number]).columns
from scipy.stats import zscore
df = df[(zscore(df[numerical_columns]) < 3).all(axis=1)]

---

# Converting data types:
Convert columns to appropriate data types like datetime, integer, or float for better processing.

Example 1: Convert a column to datetime:
datetime_columns = ['date_column']  # Replace with actual datetime columns
for col in datetime_columns:
    if col in df.columns:
        df[col] = pd.to_datetime(df[col])

Example 2: Convert a column to integer:
integer_columns = ['int_column']  # Replace with actual integer columns
for col in integer_columns:
    if col in df.columns:
        df[col] = df[col].astype(int)

Example 3: Convert a column to float:
float_columns = ['float_column']  # Replace with actual float columns
for col in float_columns:
    if col in df.columns:
        df[col] = df[col].astype(float)

---

# Feature engineering:
Create new features by combining or extracting information from existing ones.

Example 1: Create a new feature by multiplying two columns:
if 'column1' in df.columns and 'column2' in df.columns:
    df['new_feature'] = df['column1'] * df['column2']

Example 2: Extract year, month, and day from a datetime column:
datetime_columns = ['date_column']  # Replace with actual datetime columns
for col in datetime_columns:
    if col in df.columns:
        df[f'{col}_year'] = df[col].dt.year
        df[f'{col}_month'] = df[col].dt.month
        df[f'{col}_day'] = df[col].dt.day

---

# Removing unwanted columns:
Unnecessary columns can be dropped to clean the dataset.

Example:
columns_to_remove = ['column_to_remove1', 'column_to_remove2']
df.drop(columns=[col for col in columns_to_remove if col in df.columns], inplace=True)

---

# Sorting data:
Sort rows by the values of a specific column.

Example:
if 'column_name' in df.columns:  # Replace with actual column name
    df.sort_values(by='column_name', ascending=True, inplace=True)

---

# Aggregating data:
Group data by a column and apply an aggregate function.

Example: Group by a column and calculate the mean:
if 'group_column' in df.columns and 'value_column' in df.columns:  # Replace with actual columns
    grouped_df = df.groupby('group_column')['value_column'].mean().reset_index()

---

# Splitting data:
Split the dataset into training and testing sets for machine learning.

Example:
from sklearn.model_selection import train_test_split
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
